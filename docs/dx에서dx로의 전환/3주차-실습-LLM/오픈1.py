#conda activate llm_env
#pip install openai


MYKEY="YOUR_OPENAI_API_KEY"

import openai
print(openai.__version__)



from openai import OpenAI
import json

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (API í‚¤ëŠ” í™˜ê²½ ë³€ìˆ˜ì—ì„œ ìë™ ë¡œë“œë¨)
client = OpenAI(api_key=MYKEY)

def run_chat_example():
    """ì±—ë´‡ ëŒ€í™” ì˜ˆì œ ì‹¤í–‰"""
    print("--- 1. ì±—ë´‡ ëŒ€í™” ì˜ˆì œ ì‹œì‘ ---")

    # ëŒ€í™” ê¸°ë¡ (History)ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ê³¼í•™ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹µë³€ì€ í•­ìƒ í•œêµ­ì–´ë¡œ í•´ ì£¼ì„¸ìš”."},
        {"role": "user", "content": "íƒœì–‘ì´ ë¹›ë‚˜ëŠ” ì›ë¦¬ëŠ” ë¬´ì—‡ì¸ê°€ìš”? ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ ì£¼ì„¸ìš”."}
    ]

    # ì²« ë²ˆì§¸ ìš”ì²­
    response1 = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages
    )

    # ì‘ë‹µ ì¶œë ¥ ë° ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    answer1 = response1.choices[0].message.content
    print(f"ğŸ¤– AI ì‘ë‹µ (1): {answer1}")
    messages.append({"role": "assistant", "content": answer1})

    # ë§¥ë½ì„ ì´ì–´ê°€ëŠ” ë‘ ë²ˆì§¸ ì§ˆë¬¸
    user_question2 = "ê·¸ ì—ë„ˆì§€ê°€ ì§€êµ¬ê¹Œì§€ ì˜¤ëŠ” ë° ì–¼ë§ˆë‚˜ ê±¸ë¦¬ë‚˜ìš”?"
    print(f"\nğŸ‘¤ ì‚¬ìš©ì ì§ˆë¬¸ (2): {user_question2}")
    messages.append({"role": "user", "content": user_question2})

    # ë‘ ë²ˆì§¸ ìš”ì²­
    response2 = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages
    )

    # ì‘ë‹µ ì¶œë ¥
    answer2 = response2.choices[0].message.content
    print(f"ğŸ¤– AI ì‘ë‹µ (2): {answer2}")
    print("--- ì±—ë´‡ ëŒ€í™” ì˜ˆì œ ì¢…ë£Œ ---\n")

run_chat_example()