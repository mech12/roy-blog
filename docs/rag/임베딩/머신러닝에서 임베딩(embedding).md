---
layout: default
title: 머신러닝에서 임베딩
parent: 임베딩
grand_parent: RAG
nav_order: 1
---

머신러닝에서 **임베딩(embedding)** 은 고차원·희소(sparse)한 데이터를 의미를 유지한 채 **저차원·밀집(dense) 벡터**로 변환한 표현 방식이다.

> 원래 데이터는 머신러닝 모델이 바로 이해하기 어려우니, 숫자 벡터로 바꿔서 의미를 담도록 표현한 것.

## 왜 임베딩을 쓰는가?

머신러닝 모델 대부분은 **수치 벡터**를 입력으로 받는다. 문자열, 카테고리, 단어, 이미지 패치 등은 바로 학습할 수 없다.

임베딩을 사용하면:
- 고차원 데이터 → 저차원 벡터
- 희소 벡터 → 밀집 벡터
- 의미적으로 비슷한 것끼리 → 비슷한 벡터로 위치

## 임베딩이 필요한 대표 상황

### 1. 범주형 변수 (Categorical Features)

예: 직업, 나이대, 지역, 상품 ID 등

One-hot encoding은 차원이 매우 커지며 의미를 담지 못한다. 그래서 **Embedding Layer**를 사용한다 (특히 추천 시스템에서).

```text
User ID: 1234 → [0.12, -0.44, 1.02, …]
Item ID: 9981 → [0.88, 0.03, -0.55, …]
```

비슷한 유저/상품은 비슷한 벡터가 생성된다.

### 2. 자연어 처리 (NLP)

단어/문장을 벡터로 표현하는 기술:
- Word2Vec
- GloVe
- FastText
- BERT 임베딩
- GPT 임베딩

```text
king  → [0.5, 0.1, 0.7, …]
queen → [0.48, 0.12, 0.68, …]

king - man + woman ≈ queen
```

### 3. 추천 시스템 (Recommender System)

유저, 아이템을 임베딩 공간에 위치시키면 유사도(코사인 유사도 등)를 통해 추천 가능.

- **유저 임베딩**: 사용자의 선호도 표현
- **아이템 임베딩**: 콘텐츠 특성/장르 등 표현

### 4. 이미지/오디오 임베딩

CNN, Vision Transformer 등에서 이미지 → 벡터 변환

예: 이미지 검색, 얼굴 인식 → 비슷한 이미지끼리 가까운 벡터 위치

## 임베딩의 핵심 특징

| 특성 | 설명 |
|------|------|
| 밀집 벡터 | 대부분의 값이 0이 아닌 dense vector |
| 저차원 | 효율적 처리 (일반적으로 16~1024차원) |
| 의미 보존 | 유사 데이터는 가까운 벡터로 표현 |
| 학습 가능 | 네트워크가 end-to-end로 학습함 |
| 일반화 능력 | 보지 못한 데이터도 표현 가능 |

## 임베딩을 사용하는 이유

1. **차원 축소 효과**: CPU/GPU 메모리 절약 + 학습 속도 증가
2. **높은 정보력**: 희소한 원-핫 벡터보다 훨씬 정보력이 높음
3. **의미적 유사성**: 데이터 간 의미적 유사성을 수치로 표현
4. **End-to-end 학습**: 딥러닝과 결합하여 end-to-end 학습 가능

## 코드 예시

```python
embedding = Embedding(input_dim=10000, output_dim=64)

word_id = 123
vector = embedding(word_id)
# → shape (64,) 벡터
```

단어 ID 123 → 64차원 의미 벡터로 변환됨.

## 요약

> **임베딩** = 의미를 보존한 채 데이터를 저차원 벡터로 표현하는 기술. 머신러닝 모델이 '이해할 수 있는 형태'로 만드는 핵심 단계.
